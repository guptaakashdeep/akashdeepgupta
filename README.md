# Hi! I'm Akashdeep <img src="assets/Hi.gif" width="30px">

[![Website Badge](https://img.shields.io/badge/guptaakashdeep.com-970BF3?style=for-the-badge&logo=ghost&logoColor=%23F7DF1E&link=https://guptaakashdeep.com)](https://guptaakashdeep.com)
[![Linkedin Badge](https://img.shields.io/badge/guptaakashdeep-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white&link=https://www.linkedin.com/in/guptaakashdeep/)](https://www.linkedin.com/in/guptaakashdeep/)
[![Medium Badge](https://img.shields.io/badge/@geekfrosty-12100E?style=for-the-badge&logo=medium&logoColor=white&link=https://medium.com/@geekfrosty)](https://medium.com/@geekfrosty)
[![Twitter Badge](https://img.shields.io/badge/@geekfrosty-%23000000.svg?style=for-the-badge&logo=X&logoColor=white&link=https://twitter.com/geekfrosty)](https://twitter.com/geekfrosty)
[![Gmail Badge](https://img.shields.io/badge/Gupta.akashdeep9-D14836?style=for-the-badge&logo=gmail&logoColor=white&link=mailto:gupta.akashdeep9@gmail.com)](mailto:gupta.akashdeep9@gmail.com)

I am a proactive Senior Data Engineer with a keen focus on optimizing and architecting robust, scalable data solutions. I am a developer by ‚ù§Ô∏è. 

I love making generalized solutions to a problem as a framework so that it can be used by wider audience.

### My Digital Garden üå±
I write a weekly tech newsletter on my [website](https://guptaakashdeep.com). The main purpose of this newsletter is to help people become a better Data Engineer by helping them in upgrading there skills to the next level while learning new things in the data space myself on the way. 


### Tech Stack
- Apache Spark
- AWS
- Apache Airflow
- Apache Iceberg
- Databricks
- Delta Lake
- Python
- Java

### My GitHub Repositories
- [SparkExceptionLogger](https://github.com/guptaakashdeep/SparkExceptionLogger) - A Custom Spark Exception Logger written in Python to log all the exception details to be viewed on an Athena Table.
- [easy-alterator](https://github.com/guptaakashdeep/easy-alterator) - A utility for altering v1 Parquet External tables which uses AWS Glue Catalog as Hive metastore. Implemeted using AWS Boto3.
- [backfeed-generator](backfeed-generator) - Airflow Workflow for generating a gzipped feed csv file from an Hive/Athena table along with checksum, DDL and control file. This implementation is via Python, Apache Spark and Bash script.
- [WAP-Implementation](https://github.com/guptaakashdeep/WAP-implementation) - Write Audit Publish Data Quality Pattern implementation using Apache Spark with Apache Iceberg Tables on AWS with AWS Glue Catalog for both Icerberg version < 1.2.0 and version >= 1.2.0 . Also includes Auditing data using AWS PyDeequ.
- [pydeequ-on-aws](https://github.com/guptaakashdeep/pydeequ-on-aws) - Contains code exaples for PyDeequ to test your data quality at scale. Covers all the components present in PyDeequ.
- [oft-concepts-via-code](https://github.com/guptaakashdeep/oft-concepts-via-code) - Contains code examples for understanding different concepts of Open Format Tables like Apache Iceberg with Apache Spark.
- [athena-view-boto3](https://github.com/guptaakashdeep/athena-view-boto3) - Contains utility code to generate Athena view programatically. Currently, there is no direct Boto3 API to generate the Athena views programatically.