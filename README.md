# Hi! I'm Akashdeep <img src="assets/Hi.gif" width="30px">

[![Website Badge](https://img.shields.io/badge/guptaakashdeep.com-970BF3?style=for-the-badge&logo=ghost&logoColor=%23F7DF1E&link=https://guptaakashdeep.com)](https://guptaakashdeep.com)
[![Linkedin Badge](https://img.shields.io/badge/guptaakashdeep-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white&link=https://www.linkedin.com/in/guptaakashdeep/)](https://www.linkedin.com/in/guptaakashdeep/)
[![Medium Badge](https://img.shields.io/badge/@geekfrosty-12100E?style=for-the-badge&logo=medium&logoColor=white&link=https://medium.com/@geekfrosty)](https://medium.com/@geekfrosty)
[![Twitter Badge](https://img.shields.io/badge/@geekfrosty-%23000000.svg?style=for-the-badge&logo=X&logoColor=white&link=https://twitter.com/geekfrosty)](https://twitter.com/geekfrosty)
[![Gmail Badge](https://img.shields.io/badge/Gupta.akashdeep9-D14836?style=for-the-badge&logo=gmail&logoColor=white&link=mailto:gupta.akashdeep9@gmail.com)](mailto:gupta.akashdeep9@gmail.com)

I am a self-driven proactive Principal Data Engineer with a keen focus on optimizing and architecting robust, scalable data solutions. I am a developer by ‚ù§Ô∏è.

I love making generalized, robust, scalable and cost-optimized solutions to a problem as a framework so that it can be used by wider audience.

## My Newsletter üå±

---

I write a weekly tech newsletter called [The Pragmatic Data Engineer's Playbook](https://guptaakashdeep.com).
The main purpose of this newsletter is to help people become a better Data Engineer by helping them in upgrading there skills to the next level.

PDEP covers the Deep Dives on Data Engineering Tech, Distributed Data Systems, Optimization Techniques, and Data Architecture.

## Tech Stack

---

- Apache Spark
- AWS
- Apache Airflow
- Apache Iceberg
- Apache Hudi
- Apache Arrow
- Apache Flink
- Apache Kafka
- Databricks
- Delta Lake
- Python
- Java
- Rust (learning)

## My GitHub Repositories

---

- [SparkExceptionLogger](https://github.com/guptaakashdeep/SparkExceptionLogger) - A Lightweight Easy-to-Integrate Custom Spark Exception Logger written in Python to log all the exception details from a Spark Job into an S3 Location or a Table that can be queried via any Query Engine like Athena, Trino, DuckDB etc.
- [Concepts-Library](https://github.com/guptaakashdeep/Concepts-Library) - A collection of practical examples and implementations showcasing key concepts for Apache Spark and Apache Airflow.
- [spark-minio-project](https://github.com/guptaakashdeep/spark-minio-project) - Builds a Spark Standalone Cluster on Docker in local with MinIO integration.
- [easy-alterator](https://github.com/guptaakashdeep/easy-alterator) - A utility for altering v1 Parquet External tables which uses AWS Glue Catalog as Hive metastore. Implemeted using AWS Boto3.
- [backfeed-generator](backfeed-generator) - Airflow Workflow for generating a gzipped feed csv file from an Hive/Athena table along with checksum, DDL and control file. This implementation is via Python, Apache Spark and Bash script.
- [WAP-Implementation](https://github.com/guptaakashdeep/WAP-implementation) - Write Audit Publish Data Quality Pattern implementation using Apache Spark with Apache Iceberg Tables on AWS with AWS Glue Catalog for both Icerberg version < 1.2.0 and version >= 1.2.0 . Also includes Auditing data using AWS PyDeequ.
- [pydeequ-on-aws](https://github.com/guptaakashdeep/pydeequ-on-aws) - Contains code exaples for PyDeequ to test your data quality at scale. Covers all the components present in PyDeequ.
- [otf-concepts-via-code](https://github.com/guptaakashdeep/oft-concepts-via-code) - Contains code examples for understanding different concepts of Open Table Formats like Apache Iceberg with Apache Spark.
- [athena-view-boto3](https://github.com/guptaakashdeep/athena-view-boto3) - Contains utility code to generate Athena view programatically. Currently, there is no direct Boto3 API to generate the Athena views programatically.
